{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Förberedelser\n",
    "Vi laddar in data igen och splittar i tränings/test-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Läs datafilen\n",
    "filename = './features_30_sec.csv'\n",
    "df = pd.read_csv(filename, header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa de första 5 raderna\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# välj kolumnen \"filename\"\n",
    "df.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Välj några features och plocka ut labels\n",
    "feature_names = ['chroma_stft_mean', 'rms_var', 'spectral_centroid_var']\n",
    "features = df[feature_names]\n",
    "labels = df.label\n",
    "\n",
    "# En vanlig notering för features och labels är X och y. Vi kommer att använda det här.\n",
    "X = features\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitta i train/test datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# By default resulterar train_test_split i en (random) 75%/25%-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVN - Support Vector Machine\n",
    "Som förra gången ska vi först göra fit() för att träna modellen på träningsdata, sedan predictar vi ny data.\n",
    "\n",
    "För SVN ska vi dessutom införa ännu ett steg, skalning. \n",
    "\n",
    "Vi skalar alla variabler så att de är \"lika stora\" genom att skala dem baserat på sin standardavvikelse.\n",
    "Detta är för att SVNs optimeringsmått, margin, är beroende av variablernas storlek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import DataFrame\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# StandardScaler kan du läsa mer om här\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_array = scaler.fit_transform(X_train)\n",
    "X_test_scaled_array = scaler.fit_transform(X_test)\n",
    "\n",
    " # scaler ger en array av siffror. Vi vill ha data en dataframe för att det är trevligare senare (då har vi bland annat namn på kolumner)\n",
    "X_train_scaled = DataFrame(X_train_scaled_array, columns=feature_names)\n",
    "X_test_scaled = DataFrame(X_test_scaled_array, columns=feature_names)\n",
    "\n",
    "#Initialisera en Support Vector Classifier med hyperparametern C = 1 och kernel = 'linear'\n",
    "clf = SVC(C = 1.0, kernel='linear', random_state=42)\n",
    "# Kör fit() på träningsdata för att träna modellen\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu kan vi se vad vi får för resultat av olika saker från vårt testdata\n",
    "clf.predict(X_test_scaled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Och här är facit\n",
    "y_test.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lite snyggare printat så kan man jämföra predictions med facit\n",
    "print(\"- prediction -\")\n",
    "for element in clf.predict(X_test_scaled[:10]):\n",
    "  print(element.ljust(10), end='')\n",
    "print(\"\\n- actual -\")\n",
    "for element in y_test.iloc[:10]:\n",
    "  print(element.ljust(10), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu kan vi beräkna accuracy (antal rätt/antal tester på hela test)\n",
    "\n",
    "# Baseline är slumpad gissning: 1/10 = 0.1 eftersom det finns 10 klasser\n",
    "# 'blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock'\n",
    "clf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Egen övning (5-15 min)\n",
    "Testa att ändra features och ändra parametrarna i SVN. Kolla vilka som finns här: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "Försök att slå 0.45 accurracy!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "I den egna övningen testade vi olika parametrar i SVN och det ledde till olika accurracy.\n",
    "\n",
    "Det är en ganska etablerad sanning i ML att man måste testa sig fram lite tills man får bra resultat. Detta går att göra automatiskt med grid search.\n",
    "\n",
    "Man gör ett \"grid\" med värden som datorn helt enkelt får söka igenom och sedan skriva en rapport automatiskt. Sedan kan man välja det bästa värdet, eller förfina sökningen där värdena såg ut att ge bra resultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import DataFrame\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Skala om data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_array = scaler.fit_transform(X_train)\n",
    "X_test_scaled_array = scaler.fit_transform(X_test)\n",
    "\n",
    "X_train_scaled = DataFrame(X_train_scaled_array, columns=feature_names) # scaler ger en array av siffror. Vi vill ha en dataframe (så vi har namn på kolumner)\n",
    "X_test_scaled = DataFrame(X_test_scaled_array, columns=feature_names)\n",
    "\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':[0.1, 1, 5, 10, 25, 100]}\n",
    "search = GridSearchCV(SVC(), param_grid = parameters, n_jobs=2)\n",
    "search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.cv_results_ # Printa en lista med resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search.best_params_)\n",
    "print(search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and recall\n",
    "Nu ska vi göra två olika classifiers som optimerar för de olika värdena precision och recall.\n",
    "1. En som sällan klassifierar icke-klassisk musik som klassisk musik.\n",
    "2. En som oftast klassifierar klassisk musik rätt.\n",
    "\n",
    "Men först ska vi se hur man får fram precision och recall i sklearn och som vanligt validerar vi på vårt testdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# För att lära oss leker vi med ett nytt torrt teoretiskt exempel. Vi har en klassifierare som klassar mellan 1 och 0 samt lite ground truth-data\n",
    "\n",
    "# y_true är det sanna värdet (ground truth)\n",
    "y_true = [0, 1, 0, 0, 1, 1]\n",
    "# y_pred är det värde vår modell estimerat (predicted)\n",
    "y_pred = [0, 0, 1, 0, 0, 1]\n",
    "\n",
    "# Lek runt lite med värdena ovan och få en känsla för hur precision och recall påverkas av y_true och y_pred.\n",
    "\n",
    "# Precision och recall returnerar precision och recall per \n",
    "print('recall:', recall_score(y_true, y_pred))\n",
    "print('precision:', precision_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu ska vi använda det för utdatat från vår classifier ovan\n",
    "y_our_data_true = y_test[:]\n",
    "y_our_data_pred = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eftersom precision och recall fungerar med en label åt gången, måste vi omvandla alla andra labels till samma label\n",
    "y_our_data_true = [i if i == 'classical' else 'other' for i in y_our_data_true]\n",
    "y_our_data_pred = [i if i == 'classical' else 'other' for i in y_our_data_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vi kan räkna ut precision och recall manuellt\n",
    "num_true_positive = 0\n",
    "num_true = 0\n",
    "num_predicted = 0\n",
    "for i in range(len(y_our_data_true)):\n",
    "    if y_our_data_true[i] == 'classical' and y_our_data_pred[i] == 'classical':\n",
    "        num_true_positive += 1\n",
    "    if y_our_data_true[i] == 'classical':\n",
    "        num_true += 1\n",
    "    if y_our_data_pred[i] == 'classical':\n",
    "        num_predicted += 1\n",
    "print('recall', num_true_positive/num_true)\n",
    "print('precision', num_true_positive/num_predicted)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eller använda inbyggda metrics från sklearn (notera pos_label='classical'. Det indikerar vilken som anses vara \"positiv\" träff)\n",
    "print('recall:', recall_score(y_our_data_true, y_our_data_pred, pos_label='classical'))\n",
    "print('precision:', precision_score(y_our_data_true, y_our_data_pred, pos_label='classical'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ett annat sätt att få fram alla metrics på en gång (sorry att jag tog en svårare väg först men hoppas det var instruktivt)\n",
    "# använd classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_our_data_true, y_our_data_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Då kan vi få en sammanfattning för ALLA labels precision och recall-scores\n",
    "print(classification_report(y_test[:], clf.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Egen övning\n",
    "\n",
    "\n",
    "- Det är ganska lätt att göra en classifier som har perfekt precision *eller* perfekt recall. Hur? (Kom på det själv!) Har du lust kan du koda en sådan classifier. Antingen själv eller använd sklearns classifier och ändra parametrar.\n",
    "- Läs på om f1-score. Det är en kombination mellan precision och recall som kan användas när man jämför classifiers som är bra på de olika sakerna.\n",
    "- Testa andra classifiers från sklearn https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "- Gör en så bra classifier du kan. Använd fler features, ändra hyperparametrar och testa andra classifiers från sklearn. Gör två olika som är bra på dessa olika saker \n",
    "  - a. Maximera hur bra den är på att klassifiera en särskilt genre (f1-score för den genren)\n",
    "  - b. Maximera hur bra den är på att klassifiera alla genres\n",
    "- Varför går det (oftast) inte att designa en perfekt classifier? Filosofera! Ta med dina tankar till imorgon :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
