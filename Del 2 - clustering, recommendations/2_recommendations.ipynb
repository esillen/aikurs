{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBS!! Kör inte detta lokalt utan i peach lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kör inte detta lokalt utan i notebook\n",
    "\n",
    "# Installera implicit\n",
    "pip install implicit\n",
    "\n",
    "# Starta om din kernel om du blir uppmanad till det (menyn kernel -> restart kernel...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladda upp history.json till peach lab.\n",
    "# Lägg den i samma folder som denna notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file = open('history.json')\n",
    "stuff = file.read()\n",
    "file.close()\n",
    "history = json.loads(stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titta på de första 10 elementen\n",
    "# History innehåller avsnittsinteraktioner från användare de senaste 60 dagarna.\n",
    "# Det är ett subset av alla användare (eftersom det skulle vara väldigt mycket data annars)\n",
    "# En interaktion är en spelning av ett avsnitt med ett särskilt id.\n",
    "history[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu ska vi stoppa in det i implicit-libraryt\n",
    "# Ni får gärna försöka förstå vad som händer här men det är mest kod för att få in datat på rätt sätt in i collaborative filtering-algoritmen\n",
    "\n",
    "import json\n",
    "import implicit\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from pipe_algorithms_lib.utils import log, delta\n",
    "\n",
    "FACTORS = 10\n",
    "ITERATIONS = 5\n",
    "\n",
    "\n",
    "def _remove_dups_in_list(lst):\n",
    "    return list(dict.fromkeys(lst))\n",
    "\n",
    "\n",
    "def _remove_false_none_in_list(lst):\n",
    "    return [x for x in lst if x]\n",
    "\n",
    "\n",
    "def _extract_values_from_tuples(list_of_tuples, index):\n",
    "    return list( i[index] for i in list_of_tuples)\n",
    "\n",
    "\n",
    "def _load_data():\n",
    "    file = open('history.json')\n",
    "    stuff = file.read()\n",
    "    file.close()\n",
    "    history = json.loads(stuff)\n",
    "\n",
    "    interactions = []\n",
    "    for (user_id, hist) in history:\n",
    "        for media_id in hist:\n",
    "            interactions.append((user_id, media_id))\n",
    "\n",
    "    return interactions\n",
    "\n",
    "\n",
    "def _convert_data_to_sparse_matrix(users, episodes):\n",
    "    \"\"\"\n",
    "        Create arrays to feed into the sparse matrix creation\n",
    "        We create a static rank of 1 for all episodes a user has watched\n",
    "    \"\"\"\n",
    "    watched_rating = 1\n",
    "    rating_array = np.full((len(users)), watched_rating)\n",
    "\n",
    "    users_array = np.asarray(users)\n",
    "\n",
    "    episodes_array = np.asarray(episodes)\n",
    "\n",
    "    return csr_matrix((rating_array, (users_array, episodes_array)))\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"\n",
    "        Create mappings for users and episodes\n",
    "            sparse matrix only want numbers to calculate\n",
    "            so we need to convert userID and EpisodeID to an int and then keep track of it.\n",
    "            We use dictionaries to do this dict() so we then \n",
    "            can do a very quick look up through Redis\n",
    "            ex. {0: '4230218b-dbef-3ee2-b7d2-f0bb568b2b2b'} --> \n",
    "        Create the sparse matrix which is used to train the recommendation model\n",
    "        Train the reco model\n",
    "        Save the result to redis to be fetched from an endpoint\n",
    "    \"\"\"\n",
    "    data = _load_data()\n",
    "    data = list(set(data))\n",
    "    log(f'Number of events loaded: {len(data)}')\n",
    "\n",
    "    only_users = _extract_values_from_tuples(data, 0)\n",
    "    filtered_only_users = _remove_false_none_in_list(only_users)\n",
    "    unique_only_users = _remove_dups_in_list(only_users)\n",
    "    dict_of_unique_users = dict(enumerate(unique_only_users))\n",
    "    inv_users_mapping = {v: k for k, v in dict_of_unique_users.items()}\n",
    "    users_as_ints = [inv_users_mapping[x] for x in filtered_only_users]\n",
    "\n",
    "    only_episodes = _extract_values_from_tuples(data, 1)\n",
    "    filtered_only_episodes = _remove_false_none_in_list(only_episodes)\n",
    "    unique_only_episodes = _remove_dups_in_list(only_episodes)\n",
    "    dict_of_unique_episodes = dict(enumerate(unique_only_episodes))    \n",
    "    inv_episodes_mapping = {v: k for k, v in dict_of_unique_episodes.items()}\n",
    "    episodes_as_ints = [inv_episodes_mapping[x] for x in filtered_only_episodes]\n",
    "\n",
    "    sparse_matrix = _convert_data_to_sparse_matrix(users_as_ints, episodes_as_ints)\n",
    "    log(f'Matrix shape: {sparse_matrix.shape}')\n",
    "\n",
    "    # Skapa modellen för collaborative filtering!\n",
    "    # Implicit-libraryt heter så för att det är implicita features (lyssning är implicit gillande)\n",
    "    # AlternatingLeastSquares är en av flera solvers till matrixfaktoriseringsproblemet\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=FACTORS, iterations=ITERATIONS)\n",
    "    # train the model\n",
    "    model.fit(sparse_matrix)\n",
    "\n",
    "    return model, inv_users_mapping, dict_of_unique_episodes, sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kör modellskapar-funktionen (som också spottar ut lite andra vettiga saker)\n",
    "model, inv_users_mapping, dict_of_unique_episodes, sparse_matrix = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktionen för att rekommendera till användare\n",
    "def recommend_items_to_user(model, inv_users_mapping, dict_of_unique_episodes, sparse_matrix, user_id, size):\n",
    "    user_model_id = inv_users_mapping.get(user_id)\n",
    "    if user_model_id is None:\n",
    "        return []\n",
    "\n",
    "    recs = model.recommend(user_model_id, sparse_matrix[user_model_id], N=size)\n",
    "    recs = zip(*recs)\n",
    "    rec_result = [(dict_of_unique_episodes[rec[0]], float(rec[1])) for rec in recs if dict_of_unique_episodes[rec[0]]]\n",
    "\n",
    "    return rec_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rekommendera till en användare!\n",
    "recommend_items_to_user(model, inv_users_mapping, dict_of_unique_episodes, sparse_matrix, '2bec17de-86ae-4625-a040-752ee0871d17', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Egen uppgift\n",
    "- Testa resultaten. Ser det rimligt ut?\n",
    "  - använd pythons requests-library för att kolla vad idna användaren lyssnat på innebär från SRs api https://api.sr.se/api/documentation/v2/index.html\n",
    "- Gör tutorials i Peach!\n",
    "  - kolla https://git.ebu.io/pipe/lab-tutorials\n",
    "  - kolla pipe_algorithms -> notebooks -> tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
